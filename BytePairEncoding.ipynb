{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BytePairEncoding.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM75qWQfzRhR4wfKcTdDFyU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ccwbroomfield/C-MinesweeperCS208/blob/master/BytePairEncoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4E4Gfg4j_mjn",
        "outputId": "bc6799c6-f8cd-4590-d97b-1dd5f9961705"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-1.17.0-py3-none-any.whl (306 kB)\n",
            "\u001b[K     |████████████████████████████████| 306 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.62.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.8.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.19.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 34.9 MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 51.7 MB/s \n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-2.0.2-cp37-cp37m-manylinux2010_x86_64.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 52.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Collecting huggingface-hub<1.0.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 408 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 57.7 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.2.0)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 60.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.9)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 50.6 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.6.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, huggingface-hub, datasets\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-1.17.0 frozenlist-1.2.0 fsspec-2021.11.1 huggingface-hub-0.2.1 multidict-5.2.0 xxhash-2.0.2 yarl-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset('imdb', split=\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "from collections import Counter\n",
        "def learn(text: List[str], k: int):\n",
        "  words = \"\"\n",
        "  count = Counter()\n",
        "\n",
        "  for i in range(len(text)):\n",
        "    words += text[i] + \" \"\n",
        "  words = words.replace(\" \", \"_\")\n",
        "  vocab = set(words)\n",
        "  print(vocab)\n",
        "  print(len(words))\n",
        "  for c in range(len(words) - 1):     #count adjacent pairs of things\n",
        "    if \"_\" not in words[c]:\n",
        "      count[words[c] + words[c+1]] += 1\n",
        "  print(count.most_common(10))\n",
        "\n",
        "  #for i in range(k): # I have original pairings, but need to do it more iteratively. one at a time, so that multi-char tokens can be used\n",
        "  #need to also replace all instances after updating vocab. Need to figure out efficient ways to do this\n",
        "\n",
        "  pass"
      ],
      "metadata": {
        "id": "9rTaP1g2Ed8Z"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "def segment(text: str, tokens: List[str]):\n",
        "  print(\"segment method\")\n",
        "  pass"
      ],
      "metadata": {
        "id": "bzNA9usmRRX0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn(dataset[\"text\"], 25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noSD-y6PWNw_",
        "outputId": "026ad8cf-7789-4d01-85b5-0f278ceb262e"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Y', '\\x8d', 'ã', '¢', 'Þ', 't', '7', '[', 'n', 'º', '’', '«', 'õ', '，', '\\xa0', 'ג', '~', 'P', 'á', 'À', 'a', '´', '@', 'ý', 'x', 'F', '1', '\\x91', 'ו', 'G', '¤', 'J', '.', 'H', 'å', 'L', '、', '»', '8', '5', 'æ', 'ª', 'Ð', 'E', '3', 'ı', 'M', 'd', 'É', ',', '+', 'j', '°', 'Õ', 'û', '©', 'D', 'Â', 'y', '£', '½', 'à', '★', '·', 'u', ']', 'Å', 'ô', '–', 'R', 'Ä', '^', 'K', 'ø', '4', '¾', 'מ', '*', '\\x80', 'p', '0', 'Z', 'v', 'O', 'ó', 'i', 'k', 'ú', '(', '>', 'ë', 'I', 'c', '9', 'ל', '“', \"'\", '…', '\"', 'Ö', 'N', 'ן', 'Æ', '¨', '\\x85', 'È', '″', 'r', '!', 'o', '#', 'ä', '▼', '\\\\', 'ß', '\\x95', 'f', '\\x96', '\\x97', '-', '&', '_', 'â', '\\xad', 'כ', '<', '=', 'ç', '”', 'C', 'ö', '‘', 'י', 'U', '}', 'ð', '{', 'ì', ')', 'א', 'l', 'A', '2', 'S', 'Ü', 'Ż', '\\t', 'ê', 'è', 'e', 'ğ', 'í', 'B', 'ò', ';', 'W', 'w', '¡', '|', '$', 'ñ', '\\x84', 'ō', 'h', 'q', 'm', 'X', ':', '?', 'î', 's', '`', 'ר', 'V', 'Ó', 'Q', 'z', 'Ç', '6', 'g', 'T', '/', 'b', 'Ï', 'ï', 'ü', 'é', '%'}\n",
            "32369810\n",
            "[('e_', 976514), ('s_', 689923), ('th', 659888), ('he', 566592), ('t_', 547907), ('in', 460400), ('d_', 428939), ('er', 388754), ('an', 368661), ('n_', 357561)]\n"
          ]
        }
      ]
    }
  ]
}